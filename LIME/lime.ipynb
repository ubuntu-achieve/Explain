{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像分类模型\n",
    "model = models.vgg19(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    " transforms.Resize(256),\n",
    " transforms.CenterCrop(224),\n",
    " transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "# 读取索引对应的类别\n",
    "labels_path = '../imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)\n",
    "\n",
    "def predict(imgs):\n",
    "    '''\n",
    "    img:将要预测的图像\n",
    "    '''\n",
    "    result = []\n",
    "    for img in imgs:\n",
    "        # 转换图像格式\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        transformed_img = transform(img)\n",
    "        img = transform_normalize(transformed_img)\n",
    "        img = img.unsqueeze(0)\n",
    "        prediction_score, pred_label_idx = torch.topk(F.softmax(model(img), dim=1), 1)\n",
    "        pred_label_idx.squeeze_()\n",
    "        predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
    "        #print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')\n",
    "        result.append(np.array([pred_label_idx, prediction_score.squeeze().item()]))\n",
    "        #return [(i,result[i]) for i in range(len(result))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00edd8623e114d94a759607ee75cba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca205db467244f6b86611516a11f418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12caa61c9bab45ea9cbe528c7171f7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea78c3ca927420aab0298fa55f8aee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path  = \"../Images/\"\n",
    "output_path = \"../Results/LIME\"\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)\n",
    "for image_path in os.listdir(input_path):\n",
    "    explainer = LimeImageExplainer()\n",
    "    explanation = explainer.explain_instance(\n",
    "        cv2.imread(os.path.join(input_path, image_path)),\n",
    "        predict, # classification function\n",
    "        top_labels=50,\n",
    "        hide_color=0,\n",
    "        num_samples=100)\n",
    "    #temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "    img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "    cv2.imwrite(os.path.join(output_path, './result_vgg19_'+image_path), img_boundry1*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\explain\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\explain\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 图像分类模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67171da7a834c1fb98cfaf1f0396b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5510ff13743043b283208c9c4f9ce8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9a136113014840823003a421d861f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91379048af94026a6fa5d21309aded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path  = \"../Images/\"\n",
    "output_path = \"../Results/LIME\"\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)\n",
    "for image_path in os.listdir(input_path):\n",
    "    explainer = LimeImageExplainer()\n",
    "    explanation = explainer.explain_instance(\n",
    "        cv2.imread(os.path.join(input_path, image_path)),\n",
    "        predict, # classification function\n",
    "        top_labels=50,\n",
    "        hide_color=0,\n",
    "        num_samples=100)\n",
    "    #temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "    img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "    cv2.imwrite(os.path.join(output_path, './result_resnet_'+image_path), img_boundry1*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('explain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c2fce50d50a56c82cbe91a1dfe9cb9c2b83c36c057410647070cfafea6728e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
